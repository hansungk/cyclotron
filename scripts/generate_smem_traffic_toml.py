#!/usr/bin/env python3
"""
Generate Cyclotron SMEM traffic TOML from a Radiance `.out` traffic log.

Input log format:
  [TRAFFIC] core <id> <pattern-name> finished at time <cycle>

The output contains an explicit `[[traffic.patterns]]` sequence preserving order.
"""

from __future__ import annotations

import argparse
import re
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Any

TRAFFIC_LINE_RE = re.compile(
    r"\[TRAFFIC\]\s+core\s+(?P<core>\d+)\s+(?P<name>.+?)\s+finished at time\s+(?P<cycle>\d+)\s*$"
)

STRIDED_RE = re.compile(
    r"^strided\(\s*(?P<warp>\d+)\s*,\s*(?P<lane>\d+)\s*\)@(?P<bytes>\d+)_(?P<op>[wr])$"
)
TILED_RE = re.compile(
    r"^tiled\(\s*(?P<m>\d+)\s*,\s*(?P<n>\d+)\s*\)@(?P<bytes>\d+)(?P<transpose>\.T)?_(?P<op>[wr])$"
)
SWIZZLED_RE = re.compile(
    r"^swizzled\(\s*(?P<size>\d+)\s*\)@(?P<bytes>\d+)(?P<transpose>\.T)?_(?P<op>[wr])$"
)
RANDOM_RE = re.compile(r"^random\((?P<seed>\d+)\)_(?P<op>[wr])$")


@dataclass
class TrafficLine:
    core: int
    pattern_name: str
    cycle: int


def parse_traffic_lines(path: Path, core: int) -> list[TrafficLine]:
    rows: list[TrafficLine] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        match = TRAFFIC_LINE_RE.search(raw)
        if not match:
            continue
        row_core = int(match.group("core"))
        if row_core != core:
            continue
        rows.append(
            TrafficLine(
                core=row_core,
                pattern_name=match.group("name").strip(),
                cycle=int(match.group("cycle")),
            )
        )
    return rows


def parse_pattern(
    pattern_name: str,
    random_occurrence: dict[tuple[int, str], int],
    smem_size_bytes: int,
) -> dict[str, Any]:
    match = STRIDED_RE.match(pattern_name)
    if match:
        return {
            "name": pattern_name,
            "kind": "strided",
            "req_bytes": int(match.group("bytes")),
            "op": "write" if match.group("op") == "w" else "read",
            "warp_stride": int(match.group("warp")),
            "lane_stride": int(match.group("lane")),
        }

    match = TILED_RE.match(pattern_name)
    if match:
        return {
            "name": pattern_name,
            "kind": "tiled",
            "req_bytes": int(match.group("bytes")),
            "op": "write" if match.group("op") == "w" else "read",
            "tile_m": int(match.group("m")),
            "tile_n": int(match.group("n")),
            "transpose": bool(match.group("transpose")),
        }

    match = SWIZZLED_RE.match(pattern_name)
    if match:
        return {
            "name": pattern_name,
            "kind": "swizzled",
            "req_bytes": int(match.group("bytes")),
            "op": "write" if match.group("op") == "w" else "read",
            "tile_size": int(match.group("size")),
            "transpose": bool(match.group("transpose")),
        }

    match = RANDOM_RE.match(pattern_name)
    if match:
        seed = int(match.group("seed"))
        op = "write" if match.group("op") == "w" else "read"
        key = (seed, op)
        occ = random_occurrence[key]
        random_occurrence[key] += 1

        # Radiance names random patterns as random(seed) without req size.
        # In `none.smem_test.out` ordering, first occurrence is 4B, second is 2B.
        req_bytes = 4 if occ == 0 else 2
        return {
            "name": pattern_name,
            "kind": "random",
            "req_bytes": req_bytes,
            "op": op,
            "random_min": 0,
            "random_max": smem_size_bytes // req_bytes,
            "seed": seed,
        }

    raise ValueError(f"unsupported pattern name format: {pattern_name}")


def toml_string(value: str) -> str:
    escaped = value.replace("\\", "\\\\").replace('"', '\\"')
    return f'"{escaped}"'


def render_toml(
    source_out: Path,
    patterns: list[dict[str, Any]],
    reqs_per_pattern: int,
    num_lanes: int,
    smem_base: int,
    smem_size_bytes: int,
    max_inflight_per_lane: int,
    retry_backoff_min: int,
    print_traffic_lines: bool,
    results_json: str,
    results_csv: str,
) -> str:
    lines: list[str] = []
    lines.append(f"# Auto-generated from {source_out}")
    lines.append("# Generated by scripts/generate_smem_traffic_toml.py")
    lines.append("")
    lines.append("[traffic]")
    lines.append("enabled = true")
    lines.append("lockstep_patterns = true")
    lines.append(f"reqs_per_pattern = {reqs_per_pattern}")
    lines.append(f"num_lanes = {num_lanes}")
    lines.append("")
    lines.append("[traffic.address]")
    lines.append("cluster_id = 0")
    lines.append(f"smem_base = 0x{smem_base:x}")
    lines.append(f"smem_size_bytes = {smem_size_bytes}")
    lines.append("")
    lines.append("[traffic.issue]")
    lines.append(f"max_inflight_per_lane = {max_inflight_per_lane}")
    lines.append(f"retry_backoff_min = {retry_backoff_min}")
    lines.append("")
    lines.append("[traffic.logging]")
    lines.append(f"print_traffic_lines = {'true' if print_traffic_lines else 'false'}")
    lines.append(f"results_json = {toml_string(results_json)}")
    lines.append(f"results_csv = {toml_string(results_csv)}")

    for pattern in patterns:
        lines.append("")
        lines.append("[[traffic.patterns]]")
        lines.append(f"name = {toml_string(pattern['name'])}")
        lines.append(f"kind = {toml_string(pattern['kind'])}")
        lines.append(f"req_bytes = {int(pattern['req_bytes'])}")
        lines.append(f"op = {toml_string(pattern['op'])}")

        kind = pattern["kind"]
        if kind == "strided":
            lines.append(f"warp_stride = {int(pattern['warp_stride'])}")
            lines.append(f"lane_stride = {int(pattern['lane_stride'])}")
        elif kind == "tiled":
            lines.append(f"tile_m = {int(pattern['tile_m'])}")
            lines.append(f"tile_n = {int(pattern['tile_n'])}")
            lines.append(f"transpose = {'true' if pattern['transpose'] else 'false'}")
        elif kind == "swizzled":
            lines.append(f"tile_size = {int(pattern['tile_size'])}")
            lines.append(f"transpose = {'true' if pattern['transpose'] else 'false'}")
        elif kind == "random":
            lines.append(f"random_min = {int(pattern['random_min'])}")
            lines.append(f"random_max = {int(pattern['random_max'])}")
            lines.append(f"seed = {int(pattern['seed'])}")
        else:
            raise ValueError(f"unsupported pattern kind for rendering: {kind}")

    lines.append("")
    return "\n".join(lines)


def parse_int_auto(value: str) -> int:
    return int(value, 0)


def main() -> int:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--reference-out",
        required=True,
        help="Path to Radiance traffic .out file (e.g. none.smem_test.out)",
    )
    parser.add_argument(
        "--output",
        default="config/traffic/smem_radiance.toml",
        help="Output TOML path (default: config/traffic/smem_radiance.toml)",
    )
    parser.add_argument("--core", type=int, default=0, help="Core id to parse (default: 0)")
    parser.add_argument("--reqs-per-pattern", type=int, default=4096)
    parser.add_argument("--num-lanes", type=int, default=16)
    parser.add_argument(
        "--smem-base",
        type=parse_int_auto,
        default=0x40000000,
        help="SMEM base address (accepts decimal or hex)",
    )
    parser.add_argument("--smem-size-bytes", type=int, default=128 << 10)
    parser.add_argument("--max-inflight-per-lane", type=int, default=16)
    parser.add_argument("--retry-backoff-min", type=int, default=1)
    parser.add_argument("--print-traffic-lines", action="store_true", default=True)
    parser.add_argument(
        "--results-json",
        default="logs/traffic/smem_radiance_results.json",
    )
    parser.add_argument(
        "--results-csv",
        default="logs/traffic/smem_radiance_results.csv",
    )
    args = parser.parse_args()

    reference_out = Path(args.reference_out).resolve()
    output = Path(args.output).resolve()
    rows = parse_traffic_lines(reference_out, core=args.core)
    if not rows:
        raise SystemExit(
            f"no [TRAFFIC] checkpoint lines found for core {args.core} in {reference_out}"
        )

    random_occurrence: dict[tuple[int, str], int] = defaultdict(int)
    patterns = [
        parse_pattern(
            row.pattern_name,
            random_occurrence=random_occurrence,
            smem_size_bytes=args.smem_size_bytes,
        )
        for row in rows
    ]

    output.parent.mkdir(parents=True, exist_ok=True)
    output.write_text(
        render_toml(
            source_out=reference_out,
            patterns=patterns,
            reqs_per_pattern=args.reqs_per_pattern,
            num_lanes=args.num_lanes,
            smem_base=args.smem_base,
            smem_size_bytes=args.smem_size_bytes,
            max_inflight_per_lane=args.max_inflight_per_lane,
            retry_backoff_min=args.retry_backoff_min,
            print_traffic_lines=args.print_traffic_lines,
            results_json=args.results_json,
            results_csv=args.results_csv,
        ),
        encoding="utf-8",
    )

    print(f"wrote {len(patterns)} patterns to {output}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
